{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2a9343-df5b-42f4-bbb1-c18b9bf09df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a4423d3-76ac-49c4-a31d-47eadc7625c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b27313-4194-4599-b6ab-c03c8b8034e9",
   "metadata": {},
   "source": [
    "# In this notebook we only read, clean and save data as csv. \n",
    "We don't tokenise it because with tokenised column data will take more than 100mb and we will not be able to save it to git.\n",
    "\n",
    "Also because there are multiple ways to tokenise data.\n",
    "\n",
    "So it's up to every separate model training file to tokenise the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf03f5f-5bd3-47f8-bcd6-2ee8fc0cbb90",
   "metadata": {},
   "source": [
    "## 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "659766e4-48f0-45ed-b7bd-b8c8efeedbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "DB_FILE = '/local/DSPT/data/nlp-data.db'\n",
    "con = sqlite3.connect(DB_FILE)\n",
    "cur = con.cursor()\n",
    "\n",
    "# Define the SQL query\n",
    "QUERY = \"\"\"\n",
    "    SELECT \n",
    "        Documents.DocumentID, \n",
    "        RawTexts.Text, \n",
    "        Labels.NumericValue AS Label, \n",
    "        Labels.Type AS LabelType, \n",
    "        Labels.StringValue AS LabelName,  \n",
    "        Documents.Type AS DocumentType,\n",
    "        RawTexts.LengthCharacters,\n",
    "        RawTexts.HasEmoji\n",
    "    FROM Documents\n",
    "    INNER JOIN RawTexts ON Documents.RawTextID = RawTexts.RawTextID\n",
    "    INNER JOIN Labels ON Documents.LabelID = Labels.LabelID;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load data into a DataFrame\n",
    "reviews = pd.read_sql_query(QUERY, con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42944c3c-e225-4ea3-a732-77809662ec49",
   "metadata": {},
   "source": [
    "## 2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6966e8-9a1d-4dc8-9cf3-f9c7dcde186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    text = re.sub(r'_', '', text)\n",
    "    return text\n",
    "\n",
    "# Clean the text data\n",
    "reviews['cleaned_text'] = reviews['Text'].apply(clean_text)\n",
    "reviews = reviews[reviews['cleaned_text'] != '']\n",
    "\n",
    "# Drow rows that have None in cleaned_text column\n",
    "reviews = reviews.dropna(subset=['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4888312-afbf-48c1-a623-227d9f9bcc0b",
   "metadata": {},
   "source": [
    "### 3. Map amazon rating to -1/0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79756025-e586-483c-b328-96a83fc33419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_amazon_rating(rating):\n",
    "    if rating <= 2:\n",
    "        return -1\n",
    "    elif rating == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "reviews['LabelMapped'] = reviews.apply(lambda row: map_amazon_rating(row[\"Label\"]) if row['LabelType'] == 'StarRating' else row[\"Label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3435912-c71f-4972-8975-a76329ef15b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['LabelMapped'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0bff7c-b66b-4595-9711-b58a9f5f1be3",
   "metadata": {},
   "source": [
    "### 4. Add emoticons as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4dc4f06-882a-4e86-a29b-45891d5583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['emoticon1'] = reviews['Text'].str.contains(\":-\\)\").astype(int)\n",
    "reviews['emoticon2'] = reviews['Text'].str.contains(':-/').astype(int)\n",
    "reviews['emoticon3'] = reviews['Text'].str.contains(':-\\(').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d7456-593e-4566-af25-8b14bbc5ee51",
   "metadata": {},
   "source": [
    "### 5. Extract hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ced69f-0ffb-4e26-9388-9b1dbadcb778",
   "metadata": {},
   "source": [
    "### 5. Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f01e72d2-1085-4b30-af28-cb899d86b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv('data/prepared_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502eeb54-9b3b-4d8e-88b3-52d6f83a94a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPT",
   "language": "python",
   "name": "dspt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
